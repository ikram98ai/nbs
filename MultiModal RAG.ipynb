{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380623e7-167c-4dce-8836-227590e0ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0040b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97fc0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured import partition_pdf\n",
    "\n",
    "pdf_file_name = ''\n",
    "\n",
    "raw_elements = partition_pdf(\n",
    "    filename= pdf_file_name,\n",
    "    chunking_strategy='by_title',\n",
    "    infer_table_structure= True,\n",
    "    max_characters= 1000,\n",
    "    new_after_n_chars=1500,\n",
    "    combine_text_under_n_chars=250,\n",
    "    strategy='hi_res'\n",
    ")\n",
    "\n",
    "pdf_file_path='Ikram-DS resume.pdf'\n",
    "extract_images_from_pdf(pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1d5cc",
   "metadata": {},
   "source": [
    "## Organize text from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86f27ea-6e18-46c9-9a9e-8b21284c7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "texts = []\n",
    "\n",
    "for element in raw_elements:\n",
    "    if 'unstructured.documents.elements.Table' in str(type(element)):\n",
    "        tables.appends(str(element))\n",
    "    elif 'unstructured.documents.elements.CompositeElement' in str(type(element)):\n",
    "        texts.appends(str(element))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05e8c2",
   "metadata": {},
   "source": [
    "## Use the Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69d7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9cd119",
   "metadata": {},
   "source": [
    "## Generate Texts and Tables summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15cbe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME =  'models/gemini-1.5-pro-latest'\n",
    "model = genai.GenertiveModel(model_name=MODEL_NAME)\n",
    "\n",
    "\n",
    "def make_prompt(element):\n",
    "    return f\"\"\" You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element}\"\"\"\n",
    "\n",
    "\n",
    "def generate_text_summaries (texts, tables, summarize_texts = False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    Args:\n",
    "\n",
    "    texts:List of str\n",
    "    tables:List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    text_summaries, table_summaries = [], []\n",
    "    if texts:\n",
    "        if summarize_texts:\n",
    "            for text in texts:\n",
    "                prompt = make_prompt(text)\n",
    "                response = model.generate_content(prompt)\n",
    "                text_summaries.append(response.text)\n",
    "        else:\n",
    "            text_summaries = text\n",
    "        \n",
    "        if tables:\n",
    "            for table in tables:\n",
    "                prompt = make_prompt(table)\n",
    "                response = model.generate_content(prompt)\n",
    "                table_summaries.append(response.text)\n",
    "        else:\n",
    "            text_summaries = text\n",
    "    return text_summaries, table_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6afd71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_summaries, table_summaries = generate_text_summaries(texts,tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97e038",
   "metadata": {},
   "source": [
    "## Generate Images summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd75e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"Encodes an image to a base64 string.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64,b64encode (image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def generate_image_summaries(image_directory):\n",
    "    \"\"\"Generates summaries for images in the specified directory.\"\"\"\n",
    "    img_base64_list = [] # Store base64 encoded images\n",
    "    image_summaries = [] # Store image summaries\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "    prompt = \"\"\"You are an automotive assistant tasked with summarizing images for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw image. \\\n",
    "    Describe concisely the characteristics (shape, color), but do not infer what the image means. \\\n",
    "    Only describe the characteristics of the image you see.\"\"\"\n",
    "    \n",
    "    for filename in sorted(os.listdir(image_directory)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_directory, filename)\n",
    "            base64_image=encode_image(image_path)\n",
    "            img_base64_list.append(base64_image)\n",
    "            with PIL.Image.open(image_path) as img:\n",
    "                response = model.generate_content([prompt, img])\n",
    "                image=summaries.append(response.text)\n",
    "            \n",
    "    return image_summaries, img_base64_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc205cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = ''\n",
    "image_summaries, img_base64_list = generate_image_summaries(image_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5f1f4",
   "metadata": {},
   "source": [
    "## Setup Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62356b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "display_name=\"rag_langchain_streaming_index\",\n",
    "dimensions=768,\n",
    "approximate_neighbors_count=150,\n",
    "leaf_node_embedding_count=500,\n",
    "leaf_nodes_to_search_percent=7,\n",
    "description=\"Multimodal RAG LangChain Stream Index\",\n",
    "index_update_method=\"stream_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d512912",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint = index_endpoint.deploy_index(\n",
    "index=index, deployed_index_id=\"rag_langchain_deployed_streaming_index\" )\n",
    "index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ddac4",
   "metadata": {},
   "source": [
    "## Define a vector store with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d6fe820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vectorstore to use to index the summaries\n",
    "vectorstore = VectorSearchVectorStore.from_components(\n",
    "project_id=PROJECT_ID,\n",
    "region=LOCATION,\n",
    "gcs_bucket_name=GCS_BUCKET,\n",
    "index_id=index_id,\n",
    "endpoint_id=endpoint_id,\n",
    "embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"),\n",
    "stream_update=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc8f5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the document store\n",
    "docstore= InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "#Create the multi-vector retriever\n",
    "retriever_multi_vector_img = MultiVectorRetriever (\n",
    "vectorstore=vectorstore,\n",
    "docstore=docstore,\n",
    "id_key=id_key,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb7196a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine raw document contents\n",
    "doc_contents= texts + tables + img_base64_list\n",
    "doc_ids = [str(uuid.uuid4()) for _ in doc_contents] \n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(texts + table_summaries + image_summaries)\n",
    "]\n",
    "retriever_multi_vector_img.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "#Generate embeddings for all chunks and stream them to the vector stom\n",
    "retriever_multi_vector_img.vectorstore.add_documents(summary_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e535d5",
   "metadata": {},
   "source": [
    "## Stage 2 Q&A Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57644a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "#Create RAG chain\n",
    "\n",
    "chain_multimodal_rag = (\n",
    "    {\n",
    "    \"context\": retriever_multi_vector_img | RunnableLambda(split_image_text_types),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda (img_prompt_func)\n",
    "    | ChatGoogleGenerativeAI (\n",
    "        temperature=0, model=\"gemini-1.5-pro-latest\", max_output_tokens=1024\n",
    "    #Multi-modal LLM\n",
    "    )\n",
    "    | StroutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3db07792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multimodal search function\n",
    "def multimodal_search(query: str) -> str:\n",
    "    \"\"\"Performs a multimodal search for a given query, retrieving relevant documents and invoking a chain for generating\n",
    "        Args:\n",
    "            query: The search query string.\n",
    "        Returns:\n",
    "            The final result generated by the chain.\n",
    "    \"\"\"\n",
    "    #retriever_multi_vector_img: The retriever object for fetching relevant documents (images and text). \n",
    "    docs=retriever_multi_vector_img.invoke(query, limit=10)\n",
    "    #split image_text_types: A function to split fetched documents into separate image and tex \n",
    "    source_docs = split_image_text_types(docs)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(\"Retrieved Text Sources:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, source in enumerate (source_docs[\"texts\"]):\n",
    "        source_without_linebreaks = source.replace(\"\\n\", \"\") # Remove line breaks\n",
    "        print(f\"Retrieved chunk {1+1}: {source_without_linebreaks}\")\n",
    "    for img_data in source_docs[\"images\"]:\n",
    "        try:\n",
    "            print(\"\\n\")\n",
    "            print('_'*80)\n",
    "            print(\"\\nRetrieved Images Matching Source Documents:\")\n",
    "            print(\"=\"*80)\n",
    "            display (Image (base64.b64decode(img_data)))\n",
    "        except (TypeError, binascii.Error):\n",
    "            print(\"Error decoding or displaying an image. Skipping...\")\n",
    "    #chain_multimodal_rag: The chain object for processing and generating a result.\n",
    "    result=chain_multimodal_rag.invoke(query)\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"RAG Pipeline Summarized Answer:\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbcd03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6b784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
